ğŸ§  AI Service â€“ Shopify Analytics Agent

This service is the AI-powered analytics engine for the Shopify Analytics App.
It is responsible for understanding natural-language business questions, converting them into structured analytics plans, generating ShopifyQL queries, and returning clear, business-friendly insights.

The service is implemented using FastAPI and a local LLM (Ollama), and is designed to work as a standalone microservice consumed by a Rails API gateway.

âœ¨ Key Responsibilities

Accept natural-language questions from the backend

Use an LLM to infer intent and parameters

Generate ShopifyQL queries deterministically

Execute analytics queries (mocked for now)

Convert raw results into layman-friendly explanations

Handle malformed or hallucinated LLM output safely

ğŸ—ï¸ High-Level Architecture
Rails API
   â”‚
   â”‚  (POST /api/v1/questions)
   â–¼
FastAPI (AI Service)
   â”‚
   â”œâ”€â”€ LLM Planning (Ollama / Phi-3)
   â”‚
   â”œâ”€â”€ Agent Logic
   â”‚     â”œâ”€â”€ Intent detection
   â”‚     â”œâ”€â”€ Time-range extraction
   â”‚     â”œâ”€â”€ Validation & fallbacks
   â”‚
   â”œâ”€â”€ ShopifyQL Generation
   â”‚
   â”œâ”€â”€ Query Execution (Mocked)
   â”‚
   â””â”€â”€ Business-Friendly Explanation

ğŸ¤– Why LLM Is Used (Important Design Choice)

The LLM is NOT used to generate data or numbers.

Instead, it is used only for planning:

Classifying intent (sales, inventory, customers)

Extracting parameters (metrics, time range)

All critical logic (query generation, validation, execution) is deterministic, ensuring:

No hallucinated analytics

Predictable behavior

Production safety

This design prevents common LLM failures and is suitable for real-world analytics systems.

ğŸ§© Agent Workflow (Step-by-Step)

Receive Question

Example:
â€œWhat were my top selling products last week?â€

LLM Planning

Prompted to return:

{
  "intent": "sales",
  "metric": "quantity",
  "time_range_days": 7
}


Sanitization & Validation

Malformed or extra LLM output is ignored

Missing values fall back to deterministic defaults

ShopifyQL Generation

Query is generated based on validated plan

Query Execution

Currently mocked

Can be replaced with real Shopify Analytics API calls

Explanation Layer

Raw metrics converted into simple business language

ğŸ“‚ Folder Structure
ai-service/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py          # FastAPI endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ analytics_agent.py # Core agent logic
â”‚   â”‚   â””â”€â”€ prompts.py         # LLM prompt templates
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ ollama_client.py   # Ollama LLM wrapper
â”‚   â”‚
â”‚   â””â”€â”€ main.py                # FastAPI app entry point
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ§  Core Agent Logic

The AnalyticsAgent is responsible for:

Interpreting user intent

Validating LLM output

Generating ShopifyQL

Returning business-friendly insights

Safety Mechanisms

Extracts only the first valid JSON block from LLM output

Ignores hallucinated or irrelevant text

Applies deterministic fallbacks

Never executes unvalidated queries

ğŸ“Š Example ShopifyQL Generated
1ï¸âƒ£ Sales Analytics
FROM sales
SHOW sum(quantity) AS total_sold
GROUP BY product_title
SINCE -7d
ORDER BY total_sold DESC
LIMIT 5

2ï¸âƒ£ Inventory Risk
FROM inventory_levels
SHOW available
ORDER BY available ASC

3ï¸âƒ£ Repeat Customers
FROM customers
SHOW count(id)
WHERE orders_count > 1
SINCE -90d

ğŸ”Œ API Endpoint
POST /ask

Request

{
  "store_id": "demo-store.myshopify.com",
  "question": "What were my top selling products last week?"
}


Response

{
  "answer": "Your top selling product in the last 7 days is Product A with around 120 units sold.",
  "confidence": "medium",
  "debug": {
    "plan": {
      "intent": "sales",
      "metric": "quantity",
      "time_range_days": 7
    },
    "shopifyql": "FROM sales ..."
  }
}

âš™ï¸ LLM Configuration

Provider: Ollama (local)

Model: phi3

Reason:

Free & local

Good enough for intent classification

Demonstrates model-agnostic architecture

The model can be swapped without changing agent logic.

ğŸ§ª Error Handling Strategy

Invalid JSON â†’ fallback logic

Partial responses â†’ defaults applied

LLM instability â†’ deterministic execution

Encoding issues â†’ UTF-8 enforced at subprocess level

ğŸš§ Current Limitations (Intentional)

ShopifyQL execution is mocked

Shopify OAuth handled by Rails API

No persistent conversation memory (optional future improvement)

These trade-offs were made to prioritize design clarity and correctness, as per assignment guidance.

ğŸš€ How to Run Locally
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000


Open API docs:

http://127.0.0.1:8000/docs

âœ… Summary

This AI service demonstrates:

Clean agentic workflow design

Safe and constrained LLM usage

Clear separation of concerns

Real-world analytics reasoning

Production-minded error handling

It is designed to integrate seamlessly with a Rails-based backend and can be extended to support real Shopify Analytics APIs with minimal changes.